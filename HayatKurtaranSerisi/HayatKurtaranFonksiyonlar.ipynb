{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HayatKurtaranFonksiyonlar.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Kütüphaneler"
      ],
      "metadata": {
        "id": "Pb4QHA9dlP0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as msno\n",
        "from datetime import date\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler"
      ],
      "metadata": {
        "id": "2QuP4uT0lLPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataframe'i Kontrol için :"
      ],
      "metadata": {
        "id": "ZG-5qlYPlSq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_df(dataframe, head=8):\n",
        "  print(\"##### Shape #####\")\n",
        "  print(dataframe.shape)\n",
        "  print(\"##### Types #####\")\n",
        "  print(dataframe.dtypes)\n",
        "  print(\"##### Tail #####\")\n",
        "  print(dataframe.tail(head))\n",
        "  print(\"##### Head #####\")\n",
        "  print(dataframe.head(head))\n",
        "  print(\"##### Null Analysis #####\")\n",
        "  print(dataframe.isnull().sum())\n",
        "  print(\"##### Quantiles #####\")\n",
        "  print(dataframe.describe([0,0.05, 0.50, 0.95, 0.99, 1]).T)\n"
      ],
      "metadata": {
        "id": "C_4n_qjThtd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cat_summary :"
      ],
      "metadata": {
        "id": "Ec5xERuR7eic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cat_summary(dataframe, col_name):\n",
        "  return print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n",
        "                      \"Ratio\": 100 * dataframe[col_name].value_counts() / len(dataframe)}))\n",
        "  print(\"#######################################\")\n"
      ],
      "metadata": {
        "id": "Wq9uM7tG7hcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cat_sum_plot(dataframe, col_name, plot = False, hue = False):\n",
        "   print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n",
        "                      \"Ratio\": 100 * dataframe[col_name].value_counts() / len(dataframe)}))\n",
        "   \n",
        "   if plot:\n",
        "    if hue:\n",
        "      sns.countplot(x=dataframe[col_name], hue = col_name, data = dataframe)\n",
        "      plt.show(block=True)\n",
        "    else:\n",
        "      sns.countplot(x=dataframe[col_name], data = dataframe)\n",
        "      plt.show(block=True)"
      ],
      "metadata": {
        "id": "vwOO9Y_u7z74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nume_summary:"
      ],
      "metadata": {
        "id": "kQX44wS5hd-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def num_summary(dataframe, num_col, plot = False):\n",
        "  quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n",
        "  print(dataframe[num_col].describe(quantiles).T)\n",
        "\n",
        "  if plot:\n",
        "    dataframe[num_col].hist()\n",
        "    plt.xlabel(num_col)\n",
        "    plt.title(num_col)\n",
        "    plt.show(block = True)\n",
        "\n",
        "  print(\"\\n\\n\")"
      ],
      "metadata": {
        "id": "oaTvJR75hg9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hedef degiskenin kategorik degiskenler ile analizi için:"
      ],
      "metadata": {
        "id": "Q2pxvSoOi9Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def target_sum_with_cat(dataframe, target, categorical_col):\n",
        "  print(pd.DataFrame({\"TARGET_MEAN\" :dataframe.groupby(categorical_col)[target].mean()}))"
      ],
      "metadata": {
        "id": "j-TnNvYci8W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hedef degiskenin nümerik degiskenler ile analizi için:"
      ],
      "metadata": {
        "id": "7TJFLD-QjMUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def target_sum_with_num(dataframe, target, numerical_col):\n",
        "  print(dataframe.groupby(target).agg({numerical_col:\"mean\"}))"
      ],
      "metadata": {
        "id": "q58hA3GFjDZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kolonları çeşitlerine (numeric, categoric, cardinal) ayırmak için :\n"
      ],
      "metadata": {
        "id": "uPaDpf7blXBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grab_col_names(dataframe, cat_th=10, car_th=20): #essiz deger sayisi 10dan kucukse kategorik degisken, 20 den buyukse de kardinal degisken gibi dusunucez. \n",
        "  cat_cols = [col for col in dataframe.columns if str(dataframe[col].dtypes) in [\"category\", \"object\", \"bool\"]]\n",
        "\n",
        "  num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < 10 and dataframe[col].dtypes in [\"int\",\"float\"]]\n",
        "  \n",
        "  cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > 20 and str(dataframe[col].dtypes) in [\"category\", \"object\"]]\n",
        "\n",
        "  cat_cols = num_but_cat + cat_cols\n",
        "  cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
        "\n",
        "  num_cols = [col for col in dataframe.columns if dataframe[col].dtypes in [\"int\",\"float\"]]\n",
        "  num_cols = [col for col in num_cols if col not in cat_cols]\n",
        "\n",
        "  print(f\"Observations: {dataframe.shape[0]}\")\n",
        "  print(f\"Variables: {dataframe.shape[1]}\")\n",
        "  print(f\"Categorical Columns: {len(cat_cols)}\")\n",
        "  print(f\"Numerical Columns: {len(num_cols)}\")\n",
        "  print(f\"Categoric but Cardinal: {len(cat_but_car)}\")\n",
        "  print(f\"Numeric but Categoric: {len(num_but_cat)}\")\n",
        "\n",
        "  return cat_cols, num_cols, cat_but_car\n"
      ],
      "metadata": {
        "id": "MLFcVP7zhyTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Yuksek Korelasyonlu Degiskenlerin listesi için :\n"
      ],
      "metadata": {
        "id": "1ULieEX8laZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def high_correlated_cols(dataframe, plot= False, corr_th = 0.90):\n",
        "  corr = dataframe.corr()\n",
        "  cor_matrix = corr.abs()\n",
        "  upper_triangle_matrix = cor_matrix.where(np.triu(np.ones(cor_matrix.shape), k=1).astype(np.bool))\n",
        "  drop_list = [col for col in upper_triangle_matrix.columns if any(upper_triangle_matrix[col]>0.90)]\n",
        "  if plot:\n",
        "    sns.set(rc={'figure.figsize': (15,15)})\n",
        "    sns.heatmap(corr, cmap=\"RdBu\")\n",
        "    plt.show()\n",
        "  return drop_list"
      ],
      "metadata": {
        "id": "QhniWuDEiFi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Aykırı değerimizi saptama işlemi için:\n"
      ],
      "metadata": {
        "id": "ZiftiC4EldbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def outlier_thresholds(dataframe, col_name, q1 = 0.25, q3 = 0.75):\n",
        "  quantile1 = dataframe[col_name].quantile(q1)\n",
        "  quantile3 = dataframe[col_name].quantile(q3)\n",
        "  interquantile_range = quantile3 - quantile1\n",
        "  up_limit = quantile3 + 1.5 * interquantile_range\n",
        "  low_limit = quantile1 - 1.5 * interquantile_range\n",
        "  return low_limit, up_limit"
      ],
      "metadata": {
        "id": "wlJBzGVKiK3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Thresholdlara göre outlier var mı yok mu diye kontrol etmek için:\n"
      ],
      "metadata": {
        "id": "P7GUE-n8lgd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_outlier(dataframe, col_name):\n",
        "  low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
        "  if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "metadata": {
        "id": "47QOZShKjAAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Var olan outlierları görmek için:\n"
      ],
      "metadata": {
        "id": "Ny5BNgBBli-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grab_outliers(dataframe, col_name, index=False):\n",
        "  low, up = outlier_thresholds(dataframe, col_name)\n",
        "  if dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].shape[0] > 10:\n",
        "    print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].head())\n",
        "  else:\n",
        "    print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))])\n",
        "\n",
        "  if index:\n",
        "    outlier_index = dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].index\n",
        "    return outlier_index"
      ],
      "metadata": {
        "id": "HtOti8EXjHIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Aykırı değerleri silme işlemi gerçekleştirmek için :\n"
      ],
      "metadata": {
        "id": "mG9Uov2WloCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_outliers(dataframe, col_name, index=False):\n",
        "  low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
        "  df_without_outliers = dataframe[~((dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit))]\n",
        "  return df_without_outliers"
      ],
      "metadata": {
        "id": "yAUejTlSjMhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Baskılama yöntemi uygulayarak, aykırı değerleri low ve uplarla değiştirmek için :\n"
      ],
      "metadata": {
        "id": "uMl_rSv4lr35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Atama yapmamıza gerek yok çünkü fonksiyonun içerisinde kullandığımız loc yapısından dolayı kalıcı değişiklik yapıyor olacak.\n",
        "def replace_with_thresholds(dataframe, variable):\n",
        "  low_limit, up_limit = outlier_thresholds(dataframe, variable)\n",
        "  dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n",
        "  dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit"
      ],
      "metadata": {
        "id": "HCs5ohkIjRb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Eksikliğe sahip verilerin seçilmesi için:"
      ],
      "metadata": {
        "id": "PKXPoUNTlHtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def missing_values_table(dataframe, na_name=False): #na_name eksik değerlerin bullunduğu değişkenlerin ismi\n",
        "  na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n",
        "  n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n",
        "  ratio = (dataframe[na_columns].isnull().sum()/dataframe.shape[0] *100).sort_values(ascending=False)\n",
        "  missing_df=pd.concat([n_miss, np.round(ratio,2)], axis=1, keys=['n_miss','ratio']) #concat ile birleştiriyoruz.\n",
        "  print(missing_df, end=\"\\n\")\n",
        "  if na_name:\n",
        "    return na_columns"
      ],
      "metadata": {
        "id": "04J7ATCBkxYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eksik değerlerin bağımlı değişken ile analizi için:\n"
      ],
      "metadata": {
        "id": "IZBEV4HqheG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tahmine dayalı atama ile doldurma\n",
        "def missing_vs_target(dataframe, target, na_columns):\n",
        "  temp_df = dataframe.copy() #dataframe in bir kopyasını oluşturduk. İstersek oluşturmayadabiliriz. Orjinal veriler elinizde kalsın istiyorsanız.\n",
        "  for col in na_columns: #boş kolonlar arasında geziyoruz.\n",
        "    temp_df[col +\"_NA_FLAG\"] = np.where(temp_df[col].isnull(), 1, 0) # İlgili kolonların boş değerler barındırdığını belirtmek amacıyla sonuna _NA_FLAG ekleyerek işaretledik. Bu değerlere kolonda boş değerlerin yerine 1, dolu değerlerin yerine 0 atadık.\n",
        "  \n",
        "  na_flags = temp_df.loc[:, temp_df.columns.str.contains(\"_NA_\")].columns #Flagli kolonları; loc kullanarak bütün sütunları al, kolonlardan da içerisinde \"_NA_\" bulunanları al diyerek na_flags içerisine atadık.\n",
        "  for col in na_flags:#na bulunan kolonları gez.\n",
        "    print(pd.DataFrame({\"TARGET_MEAN\": temp_df.groupby(col)[target].mean(), #Bu kolonlara göre grupby a alarak target ın ortalamasını yaz.  \n",
        "                        \"Count\" : temp_df.groupby(col)[target].count()}), end=\"\\n\\n\\n\") #Bu kolonlara göre grupby a alarak target ın countunu yaz."
      ],
      "metadata": {
        "id": "OZ3YJRtThjDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label encoder işlemi için:"
      ],
      "metadata": {
        "id": "c6xLSoZP3y_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_encoder(dataframe, binary_col):\n",
        "  labelencoder=LabelEncoder()\n",
        "  dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n",
        "  return dataframe"
      ],
      "metadata": {
        "id": "7KmlZl0xhlHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Hot Encoder için :"
      ],
      "metadata": {
        "id": "qpQGDWvt33lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoder(dataframe, categorical_cols, drop_first=True):\n",
        "  dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n",
        "  return dataframe"
      ],
      "metadata": {
        "id": "WpFwMXKS3_Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rare Analyser -> Elimizde bol kategorik değişkenli bir veri seti olduğunda çok işe yarar ve kullanılır."
      ],
      "metadata": {
        "id": "0oWA5IVtCCNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rare_analyser(dataframe, target, cat_cols):\n",
        "  for col in cat_cols:\n",
        "    print(col,\":\", len(dataframe[col].value_counts()))#ilgili kategorik değişkenin kaç sınıfı olduğu bilgisi.\n",
        "    print(pd.DataFrame({\"COUNT\":dataframe[col].value_counts(),#sınıf frekansları\n",
        "                        \"RATIO\":dataframe[col].value_counts()/len(dataframe),#sınıf oranları\n",
        "                        \"TARGET_MEAN\":dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\") #target yani bağımlı değişkene göre groupby işlemi."
      ],
      "metadata": {
        "id": "SiOghhpaCSBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Label Encoder işlemi için:\n"
      ],
      "metadata": {
        "id": "vG1YTA1XjkHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_encoder(dataframe, binary_col):\n",
        "  labelencoder=LabelEncoder()\n",
        "  dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n",
        "  return dataframe"
      ],
      "metadata": {
        "id": "Iyqq5wD7jkfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#One Hot Encoder işlemi için:"
      ],
      "metadata": {
        "id": "LNH2LwVOjtOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoder(dataframe, categorical_cols, drop_first=True):\n",
        "  dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n",
        "  return dataframe"
      ],
      "metadata": {
        "id": "dP4dK2kdjtaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rare Analiz işlemi için:"
      ],
      "metadata": {
        "id": "9w0SkUK7j9gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rare_analyser(dataframe, target, cat_cols):\n",
        "  for col in cat_cols:\n",
        "    print(col,\":\", len(dataframe[col].value_counts()))#ilgili kategorik değişkenin kaç sınıfı olduğu bilgisi.\n",
        "    print(pd.DataFrame({\"COUNT\":dataframe[col].value_counts(),#sınıf frekansları\n",
        "                        \"RATIO\":dataframe[col].value_counts()/len(dataframe),#sınıf oranları\n",
        "                        \"TARGET_MEAN\":dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")"
      ],
      "metadata": {
        "id": "pXQG1Ac7j3VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rare Encoder işlemi için:"
      ],
      "metadata": {
        "id": "ARciT1MRkFjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rare_encoder(dataframe, rare_perc):\n",
        "  temp_df = dataframe.copy()\n",
        "  #eğer fonksiyona girilen rare oranından daha düşük sayıda herhangi bir, bu kategorik değişkenin sınıf oranı varsa aynı zamanda bu bir kategorik değişkense bunları rare columnları olarak getir.\n",
        "  rare_columns = [col for col in temp_df.columns if temp_df[col].dtypes == \"O\" and (temp_df[col].value_counts()/len(temp_df)<rare_perc).any(axis=None)]\n",
        "\n",
        "  for var in rare_columns:\n",
        "    tmp = temp_df[var].value_counts()/ len(temp_df) #alınan rare columlarının değerlerini toplam gözlem sayısına oranını alıyoruz. İlgili rare değişkeni için sınıf oranları hesaplandı.\n",
        "    rare_labels = tmp[tmp<rare_perc].index #Çalışmanın başında verilen orandan daha düşük orana sahip olan sınıflarla veri setine indirge ve bunları rare_labelde tut. \n",
        "    temp_df[var] = np.where(temp_df[var].isin(rare_labels), \"Rare\", temp_df[var]) #eğer rare columnlardan birinde eğer rare label olma durumunda bunların yerine \"Rare\" yaz. Değilse olduğu gibi kalacak.\n",
        "    #Pandas isin()yöntemi, veri çerçevelerini filtrelemek için kullanılır. isin() yöntem, belirli bir sütunda belirli bir (veya Çoklu) değere sahip satırların seçilmesine yardımcı olur.\n",
        "  return temp_df"
      ],
      "metadata": {
        "id": "g9IuTPnfkFx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# İki grubun oranını hesaplamak için :"
      ],
      "metadata": {
        "id": "XeZnzpuVSG80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "test_stat, pvalue = proportions_ztest(count = [df.loc[df[\"NEW_CABIN_BOOL\"] == 1, (\"Survived\")].sum(),\n",
        "                                             df.loc[df[\"NEW_CABIN_BOOL\"] == 0, \"Survived\"].sum()],\n",
        "                                      nobs = [df.loc[df[\"NEW_CABIN_BOOL\"] == 1, \"Survived\"].shape[0],\n",
        "                                             df.loc[df[\"NEW_CABIN_BOOL\"] == 0, \"Survived\"].shape[0]])"
      ],
      "metadata": {
        "id": "SXLjsaaJSbHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Yeni türettiğimiz değişkenlere bakalım istersek:\n"
      ],
      "metadata": {
        "id": "PktGxyKI3R-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "def plot_importance(model,features, num=len(X),save=False):\n",
        "  feature_imp = pd.DataFrame({\"Value\" : model.feature_importances_, \"Feature\" : features.columns})\n",
        "  plt.figure(figsize=(10,10))\n",
        "  sns.set(font_scale=1)\n",
        "  sns.barplot(x=\"Value\", y = \"Feature\", data=feature_imp.sort_values(by=\"Value\",\n",
        "                                                                     ascending=False)[0:num])\n",
        "  plt.title(\"Features\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "  if save:\n",
        "    plt.savefig(\"importances.png\")\n"
      ],
      "metadata": {
        "id": "f69-bko63QAH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}