{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GradientDescentIleDogrusalRegresyon.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "pd.set_option(\"display.float_format\", lambda x: \"%.2f\" % x)"
      ],
      "metadata": {
        "id": "7-AB75RiBqXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-yDwxU4y0Bf"
      },
      "outputs": [],
      "source": [
        "#Cost function\n",
        "def cost_func(Y, b, w, X):\n",
        "  m = len(Y) # Gözlem sayısı, bütün gözlem birimlerini gezip hatayı bulacağımızdan dolayı gerekli.\n",
        "  sse = 0\n",
        "\n",
        "  for i in range(0, m): #Bütün gözlem birimlerini gez,\n",
        "    y_hat = b + w * float(X.iloc[i].values) # verilen b, w değerlerine göre y değeri hesaplanacak.\n",
        "    y = float(Y.iloc[i].values) # gerçek y değerleri\n",
        "    sse += (y_hat - y ) ** 2 # farkının karesini alır ve eklersek toplam hata hesabını yaparız.\n",
        "  \n",
        "  mse = sse / m # en sonda da m e bölerek ortalama hatayı buluruz.\n",
        "  return mse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_weight(Y, b, w, X, learning_rate):\n",
        "\n",
        "  m = len(Y)\n",
        "\n",
        "  b_deriv_sum = 0\n",
        "  w_deriv_sum = 0\n",
        "\n",
        "  for i in range(0, m):#bütün gözlem birimlerine b ve w için işlem yapıyoruz.\n",
        "    y_hat = b + w * float(X.iloc[i].values)\n",
        "    y = float(Y.iloc[i].values)\n",
        "    b_deriv_sum += (y_hat - y) # b için türev sonucu\n",
        "    w_deriv_sum += (y_hat - y) * float(X.iloc[i].values) #w için olan türev sonucu\n",
        "\n",
        "  new_b = b - (learning_rate * 1 / m * b_deriv_sum)\n",
        "  new_w = w - (learning_rate * 1 / m * w_deriv_sum)\n",
        "  return new_b, new_w"
      ],
      "metadata": {
        "id": "rMMgliLL3hjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(Y, initial_b, initial_w, X, learning_rate, num_iters):\n",
        "\n",
        "  \n",
        "  print(\"Starting gradient descent at b ={0}, w = {1}, mse = {2}\".format(initial_b, initial_w, #İşlem yapmadan önce ilk değerlerimizi getiriyoruz. Karşılaştırmak için.\n",
        "                                                                         cost_func(Y, initial_b, initial_w, X)))\n",
        "  b = initial_b #bir karışıklık olmaması adına b ve w değerlerine atama yapıyoruz.\n",
        "  w = initial_w\n",
        "  cost_history = [] #her mse değerimizi burada tutacağız.\n",
        "\n",
        "  for i in range(num_iters):\n",
        "    b, w = update_weight(Y, b, w, X, learning_rate) #learning rate oranına göre b ve w değişkenlerimizin yeni değerlerini hesaplıyoruz.\n",
        "    mse = cost_func(Y, b, w, X) # yeni değerlere göre yeni mse hatamız\n",
        "    cost_history.append(mse) \n",
        "\n",
        "    if i % 100 == 0: #Bu işlem 100 kere yapılana kadar raporlama yapıyoruz.\n",
        "      print(\"iter={:d}    b={:.2}   w={:.4f}    mse={:.4}\".format(i, b, w, mse))\n",
        "\n",
        "  print(\"After {0} iterations b = {1}, w={2}, mse={3}\". format(num_iters, b, w, cost_func(Y, b, w, X))) #Şu kadar iterasyon sonucunda en sonki b, w, mse değerlerimizi yazdırıyoruz. \n",
        "  #İlk baştaki değerlerle karşılaştırabilmek için\n",
        "  return cost_history, b, w"
      ],
      "metadata": {
        "id": "S1ztmbW75lDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"advertising.csv\")\n",
        "X = df[[\"Radio\"]]\n",
        "Y = df[[\"Sales\"]]"
      ],
      "metadata": {
        "id": "YZ8tl5EsBfUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parametre : veri setinden bulunur.\n",
        "#Hiper Parametre : Veri setinden bulunamayan, kullanıcı tarafından ayarlanması gereken parametrelerdir.\n",
        "#Örnek olarak verelim şimdilik:\n",
        "learning_rate = 0.001\n",
        "initial_b = 0.001\n",
        "initial_w = 0.001\n",
        "num_iters = 10\n",
        "\n",
        "train(Y, initial_b, initial_w, X, learning_rate, num_iters)"
      ],
      "metadata": {
        "id": "pjkuFeR9Qmp2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42e2ca1f-fd05-4f16-da27-798c99264987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting gradient descent at b =0.001, w = 0.001, mse = 255.92392306730005\n",
            "iter=0    b=0.016   w=0.3795    mse=78.16\n",
            "After 10 iterations b = 0.05137945708376413, w=0.4972772634684348, mse=67.19669096618838\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([78.16286235183698,\n",
              "  68.00692470937966,\n",
              "  67.40465935847895,\n",
              "  67.34697629889212,\n",
              "  67.3203484267101,\n",
              "  67.29550417817917,\n",
              "  67.27077503728594,\n",
              "  67.24606588921424,\n",
              "  67.22137130458634,\n",
              "  67.19669096618838],\n",
              " 0.05137945708376413,\n",
              " 0.4972772634684348)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "00U78qmLV42B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}